{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline de um processo de Deep Learning implementado em PyTorch:\n",
    "\n",
    "    1. Preparar os Dados\n",
    "    2. Definir o Modelo\n",
    "    3. Treinar o Modelo\n",
    "    4. Avaliar o Modelo\n",
    "    5. Usar o Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **MLP para classificação multiclasse**\n",
    "**Dataset Iris (flores)**\n",
    "- Dataset de imagens para previsão da espécie da flor dadas as medidas das flores\n",
    "- 3 classes com 50 instâncias cada\n",
    "- Classes: Iris Setosa, Iris Versicolour e Iris Virginica\n",
    "- 5 atributos: 4 para dimensões numéricas e o 5º a classe da flor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'iris.csv'\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    def get_splits(self, n_test=0.33):\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        return random_split(self, [train_size, test_size])\n",
    "    \n",
    "def prepare_data(path):\n",
    "    dataset = CSVDataset(path)\n",
    "    train, test = dataset.get_splits()\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "train_dl, test_dl,  train_dl_all, test_dl_all = prepare_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def visualize_data(path):\n",
    "    ...\n",
    "\n",
    "def visualize_dataset(train_dl, test_dl):\n",
    "    print(f\"Quantidade de casos de Treino:{len(train_dl.dataset)}\") \n",
    "    print(f\"Quantidade de casos de Teste:{len(test_dl.dataset)}\")\n",
    "    x, y = next(iter(train_dl))casos\n",
    "    print(f\"Shape tensor batch casos treino, input: {x.shape}, output: {y.shape}\")\n",
    "    x, y = next(iter(test_dl))  \n",
    "    print(f\"Shape tensor batch casos test, input: {x.shape}, output: {y.shape}\")\n",
    "    print(y)\n",
    "\n",
    "visualize_data(PATH)\n",
    "visualize_dataset(train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.2 Verificar balanceamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_holdout_balance(y_train, y_test):\n",
    "    ...\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    casos_treino=len(y_train) \n",
    "    casos_test=len(y_test)\n",
    "    \n",
    "    Iris_setosa_Train=np.count_nonzero(y_train == 0)\n",
    "    Iris_versicolor_Train = np.count_nonzero(y_train == 1)\n",
    "    Iris_virginica_Train = np.count_nonzero(y_train == 2)\n",
    "    Iris_setosa_Test=np.count_nonzero(y_test == 0)\n",
    "    Iris_versicolor_Test = np.count_nonzero(y_test == 1)\n",
    "    Iris_virginica_Test = np.count_nonzero(y_test == 2)\n",
    "    \n",
    "    print(\"casos_treino:\",casos_treino)\n",
    "    print(\"Iris-setosa_Train: \", Iris_setosa_Train)\n",
    "    print(\"Iris-versicolor_Train: \", Iris_versicolor_Train) \n",
    "    print(\"Iris-virginica_Train: \", Iris_virginica_Train)\n",
    "    \n",
    "    print(\"casos_test:\",casos_test)\n",
    "    print(\"Iris-setosa_Test: \", Iris_setosa_Test)\n",
    "    print(\"Iris-versicolor_Test: \", Iris_versicolor_Test)\n",
    "    print(\"Iris-virginica_Test: \", Iris_virginica_Test)\n",
    "\n",
    "    grafico=sns.barplot(x=['Iris-setosa_Train','Iris-versicolor_Train', 'Iris-virginica_Train', 'Iris-setosa_Test', 'Iris-versicolor_Test', 'Iris-virginica_Test'], \n",
    "                        y=[Iris_setosa_Train, Iris_versicolor_Train, Iris_virginica_Train, Iris_setosa_Test, Iris_versicolor_Test, Iris_virginica_Test])\n",
    "    grafico.set_title('Data balance ')\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "    \n",
    "visualize_holdout_balance(train_dl_all, test_dl_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        ...\n",
    " \n",
    "    def forward(self, X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    "\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 4), verbose=0))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc\n",
    "\n",
    "def train_model(train_dl, model):\n",
    "    liveloss = PlotLosses()\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "    for epoch in range(EPOCHS):\n",
    "        logs = {}\n",
    "        epoch_loss  = 0\n",
    "        epoch_acc  = 0\n",
    "        for i, (inputs, labels) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            yprev = model(inputs)\n",
    "            loss = criterion(yprev, labels)\n",
    "            ...\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ...\n",
    "        \n",
    "        print(f'Epoch {epoch:03}: | Loss: {epoch_loss/len(train_dl):.5f} | Acc: {epoch_acc/len(train_dl):.3f}')      \n",
    "        logs['loss'] = epoch_loss\n",
    "        logs['accuracy'] = epoch_acc/len(train_dl)\n",
    "        ...\n",
    "\n",
    "train_model(train_dl, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions = list()\n",
    "    actual_values = list()\n",
    "    for i, (inputs, labels) in enumerate(test_dl):\n",
    "        yprev = model(inputs)\n",
    "        yprev = yprev.detach().numpy()\n",
    "        actual = labels.numpy()\n",
    "        yprev = np.argmax(yprev, axis=1)\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yprev = yprev.reshape((len(yprev), 1))\n",
    "        predictions.append(yprev)\n",
    "        actual_values.append(actual)\n",
    "        break\n",
    "    predictions, actual_values = np.vstack(predictions), np.vstack(actual_values)\n",
    "    return predictions, actual_values\n",
    " \n",
    "def display_confusion_matrix(cm):\n",
    "    plt.figure(figsize = (16,8))\n",
    "    sns.heatmap(cm,annot=True,xticklabels=['Iris-setosa','Iris-versicolor','Iris-virginica'],yticklabels=['Iris-setosa','Iris-versicolor','Iris-virginica'], annot_kws={\"size\": 12}, fmt='g', linewidths=.5)\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show() \n",
    "    \n",
    "predictions, actual_values = evaluate_model(test_dl, model)\n",
    "\n",
    "acertou=0\n",
    "falhou = 0\n",
    "for r,p in zip(actual_values, predictions):\n",
    "    print(f'real:{r} previsão:{p}') \n",
    "    if r==p: acertou+=1  \n",
    "    else: falhou+=1\n",
    "\n",
    "acc = accuracy_score(actual_values, predictions)\n",
    "print(f'Accuracy: {acc:0.3f}\\n')\n",
    "print(f'acertou:{acertou} falhou:{falhou}')\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Usar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    yprev = model(row)\n",
    "    yprev = yprev.detach().numpy()\n",
    "    return yprev\n",
    "\n",
    "...\n",
    "yprev = predict(row, model)\n",
    "print('Predicted: %s (class=%d)' % (yprev, np.argmax(yprev)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
