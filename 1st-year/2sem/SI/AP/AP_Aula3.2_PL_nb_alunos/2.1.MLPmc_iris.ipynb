{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline de um processo de Deep Learning implementado em PyTorch:\n",
    "\n",
    "    1. Preparar os Dados\n",
    "    2. Definir o Modelo\n",
    "    3. Treinar o Modelo\n",
    "    4. Avaliar o Modelo\n",
    "    5. Usar o Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **MLP para classificação multiclasse**\n",
    "**Dataset Iris (flores)**\n",
    "- Dataset de imagens para previsão da espécie da flor dadas as medidas das flores\n",
    "- 3 classes com 50 instâncias cada\n",
    "- Classes: Iris Setosa, Iris Versicolour e Iris Virginica\n",
    "- 5 atributos: 4 para dimensões numéricas e o 5º a classe da flor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'iris.csv'\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        self.X = df.values[:, :-1]\n",
    "        self.y = df.values[:, -1]\n",
    "        self.X = self.X.astype('float32')\n",
    "        self.y = LabelEncoder().fit_transform(self.y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        ...\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        ...\n",
    " \n",
    "    def get_splits(self, n_test=0.33):\n",
    "        ...\n",
    "    \n",
    "def prepare_data(path):\n",
    "    dataset = CSVDataset(path)\n",
    "    train, test = dataset.get_splits()\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, test_dl, train_dl_all, test_dl_all\n",
    "\n",
    "train_dl, test_dl,  train_dl_all, test_dl_all = prepare_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = Linear(n_inputs, 10)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        self.hidden2 = Linear(10, 8)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        ...\n",
    " \n",
    "    def forward(self, X):\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        return X\n",
    "\n",
    "...\n",
    "print(summary(model, input_size=(BATCH_SIZE, 4), verbose=0))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(train_dl, model):\n",
    "    ...\n",
    "    for epoch in range(EPOCHS):\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            yprev = model(inputs)\n",
    "            loss = criterion(yprev, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "train_model(train_dl, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions = list()\n",
    "    actual_values = list()\n",
    "    for i, (inputs, labels) in enumerate(test_dl):\n",
    "        yprev = model(inputs)\n",
    "        yprev = yprev.detach().numpy()\n",
    "        actual = labels.numpy()\n",
    "        ...\n",
    "        predictions.append(yprev)\n",
    "        actual_values.append(actual)\n",
    "        break\n",
    "    predictions, actual_values = np.vstack(predictions), np.vstack(actual_values)\n",
    "    return predictions, actual_values\n",
    " \n",
    "def display_confusion_matrix(cm):\n",
    "    plt.figure(figsize = (16,8))\n",
    "    ...\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show() \n",
    "    \n",
    "predictions, actual_values = evaluate_model(test_dl, model)\n",
    "\n",
    "acertou=0\n",
    "falhou = 0\n",
    "for r,p in zip(actual_values, predictions):\n",
    "    print(f'real:{r} previsão:{p}') \n",
    "    if r==p: acertou+=1  \n",
    "    else: falhou+=1\n",
    "\n",
    "...\n",
    "print(f'Accuracy: {acc:0.3f}\\n')\n",
    "print(f'acertou:{acertou} falhou:{falhou}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Usar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, model):\n",
    "    row = Tensor([row])\n",
    "    yprev = model(row)\n",
    "    yprev = yprev.detach().numpy()\n",
    "    return yprev\n",
    "\n",
    "...\n",
    "yprev = predict(row, model)\n",
    "print('Predicted: %s (class=%d)' % (yprev, np.argmax(yprev)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
