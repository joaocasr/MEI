{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **CNN para classificação multiclasse de imagens**\n",
    "## - Visualização dos filtros e dos *featuremaps*\n",
    "**Dataset MNIST (Modified National Institute of Standards and Technology)**\n",
    "- É considerado o dataset “hello world” de *computer vision*.\n",
    "- Dataset de imagens de dígitos escritos manualmente\n",
    "- Inputs: imagens de 28x28 pixeis\n",
    "- Output: classe a representar o dígito (10 classes, dígitos 0-9)\n",
    "- 70k imagens das quais 60k são para treino e 10k para teste\n",
    "- 2 atributos: o id da imagem e o respetivo label   \n",
    "\n",
    "Vamos utilizar uma rede neuronal para classificação do dígito em cada imagem de 28x28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.transforms import Normalize\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Dropout2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    " \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C:\\\\Users\\\\joaop\\\\Documents\\\\GitHub\\\\MEI\\\\1st-year\\\\2sem\\\\SI\\\\AP\\\\class-3\\\\AP_Aula3.3_PL_nb_alunos\"\n",
    "PATH_TRAIN = \"C:\\\\Users\\\\joaop\\\\Documents\\\\GitHub\\\\MEI\\\\1st-year\\\\2sem\\\\SI\\\\AP\\\\class-3\\\\AP_Aula3.3_PL_nb_alunos\\\\mnist_train.csv\"\n",
    "PATH_TEST = \"C:\\\\Users\\\\joaop\\\\Documents\\\\GitHub\\\\MEI\\\\1st-year\\\\2sem\\\\SI\\\\AP\\\\class-3\\\\AP_Aula3.3_PL_nb_alunos\\\\mnist_test.csv\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):    \n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "         for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Preparar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose(\n",
    "        [ToTensor(), \n",
    "         Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "        ])\n",
    "test_transform = Compose(\n",
    "        [ToTensor(), \n",
    "         Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        df_set = pd.read_csv(path, header=0,encoding='utf-8')\n",
    "\n",
    "        self.x = df_set.values[:, 1:]\n",
    "        self.y = df_set.values[:, 0]\n",
    "\n",
    "        self.x = self.x.astype('float32')\n",
    "        self.y = self.y.astype('long')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.y[idx]\n",
    "        image = self.x[idx]       \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def get_TensorDataset(self):\n",
    "        x = self.x.reshape(len(self.x), 1, 28, 28)\n",
    "        xmax, xmin = x.max(), x.min()\n",
    "        x = (x - xmin)/(xmax - xmin)\n",
    "        x  = torch.from_numpy(np.array(x)).float()\n",
    "        y  = torch.from_numpy(np.array(self.y)).type(torch.LongTensor)\n",
    "        cases = torch.utils.data.TensorDataset(x,y)\n",
    "        return cases \n",
    "\n",
    "def prepare_data_loaders(path_train, path_test):\n",
    "    dataset_train = CSVDataset(path_train,transform=train_transform)\n",
    "    dataset_test = CSVDataset(path_test,transform=test_transform)\n",
    "    train = dataset_train.get_TensorDataset()\n",
    "    train_size = int(0.8 * len(train))\n",
    "    val_size = len(train) - train_size\n",
    "    train, validation = random_split(train, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    test = dataset_test.get_TensorDataset()\n",
    "    \n",
    "    train_dl = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(validation, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_dl_all = DataLoader(train, batch_size=len(train), shuffle=False)\n",
    "    val_dl_all = DataLoader(validation, batch_size=len(validation), shuffle=True)\n",
    "    test_dl_all = DataLoader(test, batch_size=len(test), shuffle=False)\n",
    "    return train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all\n",
    "\n",
    "train_dl, val_dl, test_dl, train_dl_all, val_dl_all, test_dl_all = prepare_data_loaders(PATH_TRAIN, PATH_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Visualizar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_label(label,mapping='label'):\n",
    "    if mapping == 'ext':\n",
    "        output_mapping = { 0:\"zero\", 1:\"um\", 2:\"dois\", 3:\"tres\", 4:\"quatro\", 5:\"cinco\", 6:\"seis\", 7:\"sete\", 8:\"oito\", 9:\"nove\" }\n",
    "    elif mapping == 'ext2':\n",
    "        output_mapping = { \"0\":\"zero\", \"1\":\"um\", \"2\":\"dois\", \"3\":\"tres\", \"4\":\"quatro\", \"5\":\"cinco\", \"6\":\"seis\", \"7\":\"sete\", \"8\":\"oito\", \"9\":\"nove\" }\n",
    "    else:\n",
    "        output_mapping = { 0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\", 5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"}\n",
    "    input = (label.item() if type(label) == torch.Tensor else label)\n",
    "    return output_mapping[input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_mnist_images(dl):\n",
    "    i, (inputs, targets) = next(enumerate(dl))\n",
    "    print(inputs.shape)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.grid()\n",
    "        plt.imshow(inputs[i][0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "visualize_mnist_images(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Definir o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_1(Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel_1, self).__init__()\n",
    "        self.layer1 = Sequential(Conv2d(in_channels=1, out_channels=32, kernel_size=(3,3)),\n",
    "                                 ReLU(),\n",
    "                                 MaxPool2d(kernel_size=(2,2), stride=(2,2))           \n",
    "                                )\n",
    "        self.layer2 = Sequential(Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3)),\n",
    "                                 ReLU(),\n",
    "                                 MaxPool2d(kernel_size=(2,2), stride=(2,2))           \n",
    "                                )\n",
    "        self.fc1 = Linear(in_features=5*5*32, out_features=100)\n",
    "        kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        self.fc2 = Linear(in_features=100, out_features=10)\n",
    "        xavier_uniform_(self.fc2.weight)\n",
    "        self.act2 = Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(-1, 4*4*50)\n",
    "        out = self.fc1(out)\n",
    "        out = self.act1(out)\n",
    "        out = self.fc2(out) \n",
    "        out = self.act2(out)\n",
    "        return out\n",
    "\n",
    "model = CNNModel_1()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_2(Module):\n",
    "    ...\n",
    "    \n",
    "model = CNNModel_2()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_3(Module):\n",
    "    ...\n",
    "    \n",
    "model = CNNModel_3()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel_4(Module):\n",
    "    ...\n",
    "    \n",
    "model = CNNModel_4()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "\n",
    "def train_model(h5_file, train_dl, val_dl, model, criterion, optimizer,epochs):\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(epochs):\n",
    "        logs = {}\n",
    "        model.train() \n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for inputs, labels in train_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(train_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(train_dl.dataset)\n",
    "        logs['loss'] = epoch_loss.item()\n",
    "        logs['accuracy'] = epoch_acc.item()\n",
    "            \n",
    "        model.eval()\n",
    "        running_loss  = 0.0\n",
    "        running_corrects  = 0.0\n",
    "        for inputs, labels in val_dl: \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.detach() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_loss = running_loss / len(val_dl.dataset)\n",
    "        epoch_acc = running_corrects.float() / len(val_dl.dataset)\n",
    "        logs['val_loss'] = epoch_loss.item()\n",
    "        logs['val_accuracy'] = epoch_acc.item()\n",
    "        liveloss.update(logs)\n",
    "        liveloss.send()\n",
    "    torch.save(model,h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_1 ################\n",
    "model = CNNModel_1()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 3,32,32), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "criterion = CrossEntropyLoss() \n",
    "optimizer = SGD(model.parameters(), lr=LEARNING_RATE) \n",
    "starttime = time.perf_counter()\n",
    "train_model('CNNModel_1.pth', train_dl, val_dl, model, criterion, optimizer,EPOCHS)\n",
    "endtime = time.perf_counter()\n",
    "print(f\"Tempo gasto: {endtime - starttime} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_2 ################\n",
    "model = CNNModel_2()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CNNModel_3 ################\n",
    "model = CNNModel_3()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######### CNNModel_4 ################\n",
    "model = CNNModel_4()\n",
    "print(summary(model, input_size=(BATCH_SIZE, 1,28,28), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Avaliar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(test_dl, model):\n",
    "    predictions = list()\n",
    "    actual_values = list()\n",
    "    for inputs, labels in test_dl:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        yprev = model(inputs)\n",
    "        yprev = yprev.detach().cpu().numpy()\n",
    "        actual = labels.cpu().numpy()\n",
    "        yprev = np.argmax(yprev, axis=1)\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yprev = yprev.reshape((len(yprev), 1))\n",
    "        predictions.append(yprev)\n",
    "        actual_values.append(actual)\n",
    "        break\n",
    "    predictions, actual_values = np.vstack(predictions), np.vstack(actual_values)\n",
    "    return actual_values, predictions\n",
    "\n",
    "def display_predictions(actual_values, predictions ):\n",
    "    acertou=0\n",
    "    falhou = 0\n",
    "    primeiros=0\n",
    "    for r,p in zip(actual_values, predictions):\n",
    "        if primeiros <20:\n",
    "            print(f'real:{r} previsão:{p}') \n",
    "            primeiros +=1\n",
    "        if r==p: acertou+=1  \n",
    "        else: falhou+=1\n",
    "\n",
    "    corrects = np.sum(predictions == actual_values)\n",
    "    acc = corrects / len(test_dl.dataset)\n",
    "    acc = accuracy_score(actual_values, predictions)\n",
    "    print(f'Accuracy: {acc:0.3f}\\n')\n",
    "    print(f'acertou:{acertou} falhou:{falhou}')\n",
    "\n",
    "    acc = accuracy_score(actual_values, predictions)\n",
    "    print(f'Accuracy: {acc:0.3f}\\n')\n",
    "    print(f'acertou:{acertou} falhou:{falhou}')\n",
    "\n",
    "def display_confusion_matrix(cm,list_classes):\n",
    "    plt.figure(figsize = (16,8))\n",
    "    sns.heatmap(cm,annot=True,xticklabels=list_classes,yticklabels=list_classes, annot_kws={\"size\": 12}, fmt='g', linewidths=.5)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show() \n",
    "\n",
    "model= torch.load('CNNModel_1.pth')\n",
    "actual_values, predictions = evaluate_model(test_dl_all, model)\n",
    "\n",
    "display_predictions(actual_values, predictions )\n",
    "print(classification_report(actual_values, predictions))\n",
    "cr =classification_report(actual_values, predictions, output_dict=True)\n",
    "list_classes=[output_label(n,'ext2') for n in list(cr.keys())[0:10] ] \n",
    "cm = confusion_matrix(actual_values, predictions)\n",
    "\n",
    "print (cm)\n",
    "display_confusion_matrix(cm,list_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Usar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_show(img, legenda): \n",
    "    img=img.cpu()\n",
    "    plt.axis('off')\n",
    "    plt.title(legenda)\n",
    "    plt.grid(b=None)\n",
    "    plt.imshow(img[0,0], cmap=plt.get_cmap('gray'))\n",
    "    ...\n",
    "\n",
    "def make_prediction(model, img): \n",
    "    img = img.reshape(1, 1, 28, 28) \n",
    "    print(img.shape)\n",
    "    print(img.dtype) \n",
    "    img = img.to(device) \n",
    "    prediction = model(img).cpu().detach().numpy()[0].argmax()\n",
    "    legenda=f\"predict:{prediction}\"\n",
    "    img_show(img,legenda)\n",
    "    ...\n",
    "\n",
    "...\n",
    "model.eval()\n",
    "imagens, label = next(iter(test_dl))\n",
    "make_prediction(model,imagens[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_images(model,dataloader,num_image):\n",
    "    imagens, label = next(iter(test_dl))\n",
    "    pred = make_prediction(model,imagens[3]) \n",
    "    print(\"pred:\",pred)\n",
    "    return imagens, pred\n",
    "\n",
    "...\n",
    "model.eval()\n",
    "images, pred = show_batch_images(model,test_dl,1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_single_channel_big(t):\n",
    "    nrows = t.shape[0]*t.shape[2]\n",
    "    ncols = t.shape[1]*t.shape[3]\n",
    "    npimg = np.array(t.numpy(), np.float32)\n",
    "    npimg = npimg.transpose((0, 2, 1, 3))\n",
    "    npimg = npimg.ravel().reshape(nrows, ncols)\n",
    "    npimg = npimg.T\n",
    "    fig, ax = plt.subplots(figsize=(ncols/10, nrows/200))    \n",
    "    imgplot = sns.heatmap(npimg, xticklabels=False, yticklabels=False, cmap='gray', ax=ax, cbar=False)\n",
    "\n",
    "def plot_filters_single_channel(t):\n",
    "    ...\n",
    "    ncols = 12\n",
    "    nrows = 1 + nplots//ncols\n",
    "    npimg = np.array(t.numpy(), np.float32) \n",
    "    count = 0\n",
    "    fig = plt.figure(figsize=(ncols, nrows))\n",
    "    for i in range(t.shape[0]): \n",
    "        for j in range(t.shape[1]):\n",
    "            count += 1\n",
    "            ax1 = fig.add_subplot(nrows, ncols, count)\n",
    "            npimg = np.array(t[i, j].numpy(), np.float32)\n",
    "            npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
    "            npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "            ax1.imshow(npimg)\n",
    "            ax1.set_title(str(i) + ',' + str(j))\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_filters_multi_channel(t):\n",
    "    num_kernels = t.shape[0]     \n",
    "    num_cols = 12 \n",
    "    num_rows = num_kernels\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows)) \n",
    "    for i in range(t.shape[0]): \n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        npimg = np.array(t[i].numpy(), np.float32) \n",
    "        npimg = (npimg - np.mean(npimg)) / np.std(npimg) \n",
    "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
    "        npimg = npimg.transpose((1, 2, 0))\n",
    "        ax1.imshow(npimg)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(str(i))\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "    plt.savefig('kernels.png', dpi=100)    \n",
    "    plt.tight_layout()\n",
    "    ...\n",
    "\n",
    "def plot_weights(layer, single_channel = True, collated = False):\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        weight_tensor = layer.weight.data \n",
    "        if single_channel:\n",
    "            if collated:\n",
    "                plot_filters_single_channel_big(weight_tensor.cpu())\n",
    "            else:\n",
    "                plot_filters_single_channel(weight_tensor.cpu() )\n",
    "        else:\n",
    "            if weight_tensor.shape[1] == 3:\n",
    "                plot_filters_multi_channel(weight_tensor.cpu())\n",
    "            else:\n",
    "                print(\"Can only plot weights with three channels with single channel = False\")\n",
    "    else:\n",
    "        print(\"Can only visualize layers which are convolutional\")\n",
    "        \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch_images(model,dataloader,num_image):\n",
    "    imagens, label = next(iter(test_dl))\n",
    "    pred = make_prediction(model,imagens[3]) \n",
    "    print(\"pred:\",pred)\n",
    "    return imagens, pred\n",
    "\n",
    "images, pred = show_batch_images(model,test_dl,1)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_layers(model):\n",
    "    conv_layers=list()\n",
    "    model_children=list(model.children())\n",
    "    for child in model_children:\n",
    "        if type(child)==Conv2d:\n",
    "            conv_layers.append(child)\n",
    "        elif type(child)==Sequential:   \n",
    "            for layer in child.children():\n",
    "                if type(layer)==Conv2d:\n",
    "                    conv_layers.append(layer)\n",
    "    ...\n",
    "\n",
    "def get_conv_pool_layers(model):\n",
    "    conv_layers=list()\n",
    "    model_children=list(model.children())\n",
    "    for child in model_children:\n",
    "        if type(child)==Conv2d or type(child)==MaxPool2d:\n",
    "            conv_layers.append(child)\n",
    "        elif type(child)==Sequential:   \n",
    "            for layer in child.children():\n",
    "                if type(layer)==Conv2d or (type(layer)==MaxPool2d):\n",
    "                    conv_layers.append(layer)\n",
    "    ...\n",
    "\n",
    "conv_layers = get_conv_pool_layers(model)\n",
    "print(conv_layers)\n",
    "print(len(conv_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percorrer_conv_layers(images, conv_layers):\n",
    "    images = images.to(device)\n",
    "    results = [conv_layers[0](images)]\n",
    "    for i in range(1, len(conv_layers)):\n",
    "        results.append(conv_layers[i](results[-1]))\n",
    "    outputs = results\n",
    "    return outputs\n",
    "\n",
    "...\n",
    "print(f\"Obtiveram-se {len(outputs)} tensores com o shape:\")\n",
    "for i in range(len(outputs)):\n",
    "    print(f\"    Layer {i} - {outputs[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_featureMaps_partial(outputs,num_imagem):\n",
    "    for num_layer in range(len(outputs)):\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        layer_viz = outputs[num_layer][num_imagem, :, :, :]\n",
    "        layer_viz = layer_viz.data\n",
    "        print(\"Layer \",num_layer+1)\n",
    "        for i, filter in enumerate(layer_viz):\n",
    "            if i == 18: \n",
    "                break\n",
    "            plt.subplot(3, 6, i + 1)\n",
    "            plt.imshow(filter.cpu(), cmap='gray')\n",
    "            plt.axis(\"off\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
